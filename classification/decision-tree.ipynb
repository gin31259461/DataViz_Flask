{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing the required libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Append root path on execution time that it can find setup.py\n",
    "sys.path.append(f\"{Path.cwd().parent.absolute()}/\")\n",
    "from setup import setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call setup function to connect to database\n",
    "db = setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This classification handler required parameters\n",
    "OID = 139\n",
    "skip_features = [\"年月\"]\n",
    "# target = \"信用卡交易金額[新台幣]\"\n",
    "# target = \"性別\"\n",
    "target = \"教育程度類別\"\n",
    "# target = \"產業別\"\n",
    "# target = \"信用卡交易筆數\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data from OID\n",
    "query = text(f\"SELECT * FROM [RawDB].[dbo].[D{OID}]\")\n",
    "result = db.execute(query)\n",
    "df = pd.DataFrame(result.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show origin data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory data analysis and feature engineering\n",
    "* Clean and pre-processing data\n",
    "* Split data to training sets (70% - 80%) and test sets\n",
    "* Feature engineering: category values are encoded and other suitable changes are made to the data\n",
    "* Predictive model is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names: list[str] = df.columns.to_list()\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of each columns\n",
    "numerical_column_max_min_tuple = []\n",
    "for col in column_names:\n",
    "    is_numeric = df[col].dtype == \"int64\"\n",
    "    is_category_column = len(df[col].unique()) <= 10\n",
    "    print(df[col].value_counts(), \"\\n\")\n",
    "    if is_numeric and (not is_category_column):\n",
    "        numerical_column_max_min_tuple.append([col, df[col].min(), df[col].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_column_max_min_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if columns have any null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle target and features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one target column (or called target attribute, that is, y) and drop from X (features)\n",
    "is_category_column = df[target].dtype == \"object\" or len(df[target].unique()) <= 10\n",
    "labels = [\"low\", \"middle\", \"high\"]\n",
    "discrete_bin_num = 3\n",
    "X: pd.DataFrame\n",
    "try:\n",
    "    X = df.drop([target] + skip_features, axis=1)\n",
    "except:\n",
    "    print(\"Column of target or skip features not exist in data frame\")\n",
    "feature_names = X.columns\n",
    "# If value of target column are numeric, divide it into multiple intervals (discretize)\n",
    "y = df[target].astype(\"string\") if is_category_column else pd.qcut(df[target], q=discrete_bin_num, labels=labels)\n",
    "class_names = y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare category list for encoding\n",
    "category_frame = X.select_dtypes(include=[\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding category value of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform category attribute into encoded value\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=category_frame.columns)\n",
    "X = encoder.fit_transform(X)\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in encoder.mapping:\n",
    "    print(it[\"col\"])\n",
    "    print(it[\"mapping\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After category value has been encoded\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Fitting the model, evaluating the results and visualizing the trees\n",
    "* Data totally prepared\n",
    "* Classifier is instantiated\n",
    "* Model is fit onto the data\n",
    "* Ensure the model is neither over fitting and under fitting the data\n",
    "* Evaluate classifier: confusion matrix, precision score, f1 score, recall, support scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting data into decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_counts = len(X.index)\n",
    "max_depth = 10\n",
    "is_big_data = row_counts > 10000\n",
    "min_samples_split = 0\n",
    "min_samples_leaf = 0\n",
    "if is_big_data:\n",
    "    # 確保葉節點有足夠的樣本進行有意義的分析，同時避免過度細分\n",
    "    # 100 - 1000\n",
    "    min_samples_leaf = 100\n",
    "    # 確保在分割內部節點之前有足夠的樣本數\n",
    "    # 10 - 50\n",
    "    min_samples_split = 10\n",
    "else:\n",
    "    # 確保每個葉節點至少有一些樣本進行分析\n",
    "    # 1 or 2\n",
    "    min_samples_leaf = 1\n",
    "    # 確保在內部節點的樣本數較少時也可以進行分割\n",
    "    # 2 - 5\n",
    "    min_samples_split = 2\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    splitter=\"best\",\n",
    "    max_depth=max_depth,\n",
    "    random_state=0,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    ")\n",
    "decision_tree = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = clf.predict(X_train)\n",
    "y_predict_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果某個分類目標的準確率低，代表這個目標與其他屬性的關聯性低，也就是說，其他屬性不足以準確的分類 (預測) 這個目標\n",
    "print(\"Training set score: {:.4f}\".format(accuracy_score(y_train, y_predict_train)))\n",
    "print(\"Test set score: {0:0.4f}\".format(accuracy_score(y_test, y_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export tree structure as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "\n",
    "output_file_path = f\"{Path.cwd().absolute()}/temp/temp.dot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = clf.fit(X, y)\n",
    "\n",
    "dotData = tree.export_graphviz(\n",
    "    clf,\n",
    "    out_file=output_file_path,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    max_depth=max_depth,\n",
    "    label=\"all\",\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "with open(output_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dotData = f.read()\n",
    "\n",
    "# Use graphviz lib to convert dot format to json format\n",
    "source = Source(dotData)\n",
    "jsonGraph = source.pipe(format=\"json\").decode(\"utf-8\")\n",
    "dictGraph: dict = json.loads(jsonGraph)\n",
    "result = {\"nodes\": [], \"edges\": []}\n",
    "\n",
    "# Filter needed part\n",
    "result[\"nodes\"] = list(\n",
    "    map(\n",
    "        lambda o: {\"id\": o.get(\"_gvid\"), \"labels\": o.get(\"label\").split(\"\\\\n\")},\n",
    "        dictGraph.get(\"objects\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "result[\"edges\"] = dict(\n",
    "    map(\n",
    "        lambda o: (\n",
    "            str(o.get(\"tail\")) + \"_\" + str(o.get(\"head\")),\n",
    "            {\n",
    "                \"id\": o.get(\"_gvid\"),\n",
    "                \"label\": o.get(\"headlabel\"),\n",
    "                \"head\": o.get(\"tail\"),\n",
    "                \"tail\": o.get(\"head\"),\n",
    "            },\n",
    "        ),\n",
    "        dictGraph.get(\"edges\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"nodes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"edges\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
